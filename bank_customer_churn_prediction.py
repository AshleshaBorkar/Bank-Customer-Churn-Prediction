# -*- coding: utf-8 -*-
"""Bank Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p-TyI-sWPBK9_NnqvzbhAjbAD3ImwbcZ

# Problem Statement

Customer churn, or the loss of clients, is a critical concern for banks, as retaining customers is often more cost-effective than acquiring new ones. The objective of this analysis is to develop a predictive model to identify bank customers likely to leave based on their profile and behavioral data. By proactively identifying these customers, banks can implement targeted retention strategies to reduce churn and improve customer satisfaction.
"""

!pip install pandas

# Import all the necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Upload the dataset file and check the first five rows of the data to understand the dataset
data = pd.read_csv("/content/Bank_Customer_Churn_Prediction.csv")
data.head()

# Check for the dataset information, if there are any NULL values
data.info()

# Check the shape of the creditcard dataset
data.shape

# Check for missing values
missing_values = data.isnull().sum()

missing_values

# Check if there are any duplicated values, if yes, remove them
data.duplicated()

# Check the summary of the statistical properties of the numerical columns in the dataset
data.describe()

# Encode categorical variables : We have two categorical features: country and gender.
data_encoded = pd.get_dummies(data, columns=['country'], drop_first=True)

# Label encode 'gender' (Female = 0, Male = 1)
data_encoded['gender'] = data_encoded['gender'].map({'Female': 0, 'Male': 1})

# Display the encoded DataFrame
print("Encoded DataFrame:")  # Print a descriptive label
print(data_encoded)  # Print the DataFrame

# Use the display function from IPython.display
from IPython.display import display

display(data_encoded)

from sklearn.preprocessing import StandardScaler

# Select numerical columns for scaling
numerical_cols = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'credit_card',
                  'active_member', 'estimated_salary']

# Initialize StandardScaler
scaler = StandardScaler()

# Scale the selected numerical columns
data_encoded[numerical_cols] = scaler.fit_transform(data_encoded[numerical_cols])

# Use the display function from IPython.display
from IPython.display import display

display(data_encoded)

from sklearn.model_selection import train_test_split

# Define features (X) and target (y)
X = data_encoded.drop(columns=['customer_id', 'churn'])  # Drop 'customer_id' and target 'churn'
y = data_encoded['churn']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the shapes of the resulting datasets
(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Initialize the logistic regression model
model = LogisticRegression(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

# Print the accuracy of the LR model
print(f"Logistic Regression Accuracy: {accuracy * 100:.2f}%")

# Get classification report
class_report = classification_report(y_test, y_pred)

# Print the classification report
print("Classification Report:")
print(class_report)

# Get confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print the confusion matrix
print("Confusion Matrix:")
print(conf_matrix)

from sklearn.metrics import roc_curve, auc

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Confusion Matrix: To see the true positives, false positives, false negatives and false positives."""

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()

"""ROC Curve: To evaluate the model's ability to distinguish between the classes. The Receiver Operating Characteristic curve illustrates the model's performance at various threshold levels. The area under the curve (AUC) value indicates how well the model distinguishes between the two classes, with a value closer to 1 being ideal."""